
# File names which should be inputs to this benchmark.
# Unix-style globbing is supported.
input:
    path:
    - 'runs/*/*/*/*_fft*.out'
    - 'runs/*/*/*/*_rfft*.out'
    # Format of input files
    format: csv
    csv-header: 'Min, Median, Max'
    filter:
        '^TAG': drop
        '^\$PREFIX': drop
        '^======': drop
        '[\w.]+, [\w.]+, [\w.]+':

# Aggregation method (e.g. min, median, max, mean)
aggregation: mean

# Axis and series column names
axis:
- Function
- Place

series:
- Prefix

# Create another table (or Excel filter) for each value in these columns
variants:
- Arch
- Mode
  #- Size
  # TODO Size requires us to grab params from launcher

# Are higher values better?
higher-is-better: false

# Value columns
values:
- Median


# Precompute columns using lambda functions
precomputed:
    Mode: "'Serial' if row['File'].split('.')[1].split('_')[3] == 'seq' else 'Parallel'"
    Function: "row['File'].split('.')[1].split('_')[1]"
    Prefix: "(lambda p: 'Native-C' if p == 'native' else p)(row['Directory'].split('/')[-1])"
    Place: "'In-place' if len(row['File'].split('.')[1].split('_')) > 4 else 'Out-of-place'"
    Implementation: "'numpy' if row['Place'] == 'Out-of-place' else 'scipy'"
    Arch: "(row['Directory'].split('/')[-3].split('_')[-3:-2]+['Unknown'])[0]"

# Filter: require certain values for columns (after precompute and rename)
filter-in:
#    Size: [1000000]

# Filter out: require columns to NOT be certain values (after filter-keep)
filter-out:
#    Prefix: [Prefix]

# Number format in Python str.format() style, or the number of digits of
# precision to show in numbers in pretty-printed pivot tables
number-format: 2

# Do we figure out the number of decimals only once, using the max value,
# and disregard smaller precision numbers?
number-format-max-only: false

