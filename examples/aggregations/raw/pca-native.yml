# File names which should be inputs to this benchmark.
# Unix-style globbing is supported.
input:
    path:
       - 'runs/*/sklearn_native/*/*_pca*'
    format: csv
    csv-header: 'Batch,Arch,Prefix,Threads,Size,n_components,Function,Time'
    filter:
        "@ Package 'daal4py' was not found. Number of threads is being ignored": drop
        "WARNING: Number of actual iterations.*": drop
        "Tolerance: .*": drop
        '':


# Aggregation method (e.g. min, median, max, mean)
aggregation: median

# Axis and series column names
axis:
    - Function
    - Size

series:
    - Prefix

variants:
    - Arch
    - Mode

values:
    - Time

# Are higher values better?
higher-is-better: false

# Precompute columns using lambda functions
precomputed:
    #Function: "row['Function'].capitalize()"
    Mode: "'Serial' if row['Threads'] == 1 else 'Parallel'"
    Arch: "(row['Directory'].split('/')[-3].split('_')[-3:-2]+['Unknown'])[0]"

filter-out:
    svd_solver: [daal]

# Number format in Python str.format() style, or the number of digits of
# precision to show in numbers in pretty-printed pivot tables
number-format: 2

# Do we figure out the number of decimals only once, using the max value,
# and disregard smaller precision numbers?
number-format-max-only: false

