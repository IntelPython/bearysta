#
#  This is statistics aggregation recipe for Bearysta.
#
#  Install Bearysta:
#     python -m pip install git+https://github.com/IntelPython/bearysta.git
#
#  Run aggregation:
#     python -m bearysta.aggregate omnisci-query-times.yml -P
#

input:
    path: 'data/mapd_log/omnisci_server.INFO.*.log'
    format: csv
    csv-header: 'op,logID,queryID,execution_time_ms,total_time_ms'
    # Transform lines from log text into csv format. Drop other, unused lines
    filter:
        '^(?!.+ ? ([0-9]+))': append
        '^.+ ? ([0-9]+).+ stdlog sql_execute ([0-9]+) .+,"(\d+)","(\d+)"\}': 'sql_execute,\1,\2,\3,\4'
        '^(?!sql_)': drop

# Aggregation method (e.g. min, median, max, mean)
aggregation: mean

# Axis and series column names
axis:
    - queryID

#series:
#    - Prefix

values:
    - execution_time_ms
    - total_time_ms

# Create another table (or Excel filter) for each value in these columns
variants:
    - logID

# Are higher values better?
higher-is-better: false

# Number format in Python str.format() style, or the number of digits of
# precision to show in numbers in pretty-printed pivot tables
number-format: 2

# Do we figure out the number of decimals only once, using the max value,
# and disregard smaller precision numbers?
number-format-max-only: false
